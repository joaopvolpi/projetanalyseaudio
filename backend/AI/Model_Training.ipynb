{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vViiNeBbNP5w",
        "outputId": "77d761c7-d796-40a2-8237-f26c9094d696"
      },
      "outputs": [],
      "source": [
        "!pip install timm\n",
        "!python -c \"from timm import list_models; print(list_models(pretrained=True)[:5])\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT96VLItwlEN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvUHFk7vv8Pl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torchvision.transforms import ToTensor,Compose, Resize, Normalize\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from PIL import Image\n",
        "import timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev2hrWX7woN8"
      },
      "outputs": [],
      "source": [
        "# File paths\n",
        "file_path_normal = '/content/drive/MyDrive/Projetos/PoleProjet/data/images/normal/'\n",
        "file_path_abnormal = '/content/drive/MyDrive/Projetos/PoleProjet/data/images/abnormal_augmented/'\n",
        "# filepath = \"/content/drive/MyDrive/Projects/data/images/abnormal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnCNeaaB1Y1N"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        # Define default transformations: Resize, ToTensor, and Normalize\n",
        "        self.transform = transform if transform else Compose([\n",
        "            Resize((256, 256)),  # Resize images to a fixed size\n",
        "            ToTensor(),  # Convert images to tensor\n",
        "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard normalization\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')  # Convert image to RGB\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "def load_images(file_path, label):\n",
        "    images_paths = [os.path.join(file_path, file) for file in os.listdir(file_path) if file.endswith(('png', 'jpg', 'jpeg'))]  # Ensure it processes image files only\n",
        "    labels = [label] * len(images_paths)\n",
        "    return images_paths, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd2gS3ZQ1ZSj"
      },
      "outputs": [],
      "source": [
        "# Load and label images\n",
        "normal_images, normal_labels = load_images(file_path_normal, 0)  # 0 for normal\n",
        "abnormal_images, abnormal_labels = load_images(file_path_abnormal, 1)  # 1 for abnormal\n",
        "\n",
        "# Combine datasets\n",
        "images = normal_images + abnormal_images\n",
        "labels = normal_labels + abnormal_labels\n",
        "#\n",
        "# Split into training and testing sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j59dEmfW49Q8"
      },
      "outputs": [],
      "source": [
        "# Create custom datasets\n",
        "train_dataset = ImageDataset(train_images, train_labels)\n",
        "test_dataset = ImageDataset(test_images, test_labels)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFgGGNxMGuTq"
      },
      "outputs": [],
      "source": [
        "img_test = file_path_normal + 'normal_3747.png'\n",
        "\n",
        "# Open the image using Pillow\n",
        "image = Image.open(img_test)  # Replace \"example.jpg\" with your image file path\n",
        "\n",
        "# Convert the image to a NumPy array\n",
        "image_array = np.array(image)\n",
        "\n",
        "# Now, you can work with the image as a NumPy array\n",
        "print(image_array.shape)  # Print the shape of the array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWbJl2PcMVfp"
      },
      "outputs": [],
      "source": [
        "# Define the number of classes for binary classification\n",
        "NUM_FINETUNE_CLASSES = 2  # True or False\n",
        "\n",
        "# Create the model\n",
        "model = timm.create_model('mobilenetv3_large_100', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEP7lhXxJsek"
      },
      "source": [
        "### Train CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulq7DrwvSSfO"
      },
      "outputs": [],
      "source": [
        "# Assuming `train_labels` is a list or numpy array of your training labels\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "# print(class_weights)\n",
        "# Modify the loss function to include the class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHvJ52mSJrvI"
      },
      "outputs": [],
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Number of epochs for training\n",
        "num_epochs = 50  # You can adjust this\n",
        "\n",
        "model.train()  # Set the model to training mode\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Initialize tqdm progress bar\n",
        "    loop = tqdm(train_loader, total=len(train_loader), leave=False)\n",
        "\n",
        "    for images, labels in loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Update the progress bar description\n",
        "        loop.set_description(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "        loop.set_postfix(loss=running_loss/len(train_loader))\n",
        "\n",
        "    loop.close()\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WliebAXZCayJ"
      },
      "source": [
        "### Load and Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRyduzcrGmdA"
      },
      "outputs": [],
      "source": [
        "# Function to get predictions and true labels\n",
        "def get_all_preds_labels(model, data_loader):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# Get predictions and true labels\n",
        "predictions, true_labels = get_all_preds_labels(model, test_loader)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_mat = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', ax=ax, square=True)\n",
        "ax.set_xlabel('Predicted Labels')\n",
        "ax.set_ylabel('True Labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_vnjQL9hZQp"
      },
      "outputs": [],
      "source": [
        "a = []\n",
        "for file in os.listdir(file_path_abnormal):\n",
        "  a.append(file)\n",
        "len(a)*0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06kkuzL6z-dc"
      },
      "outputs": [],
      "source": [
        "t_1_p_0 = sorted([test_dataset.file_paths[i].split('/')[-1] for i in range(len(predictions)) if (predictions[i]==0 and true_labels[i]==1)])\n",
        "t_1_p_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugyt3co8Gc7w"
      },
      "source": [
        "### Model Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI5f81niDYxE"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "def model_size(model):\n",
        "    # Get the model's parameters\n",
        "    params = list(model.parameters())\n",
        "\n",
        "    # Calculate the size of the parameters in bytes\n",
        "    total_size = sum(p.numel() * p.element_size() for p in params)\n",
        "\n",
        "    # Convert bytes to megabytes (MB)\n",
        "    total_size_mb = total_size / (1024 ** 2)\n",
        "\n",
        "    return total_size_mb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_65El9tUDhl2"
      },
      "outputs": [],
      "source": [
        "num_params = count_parameters(model)\n",
        "print(f\"Number of parameters in the model: {num_params}\")\n",
        "\n",
        "model_size_mb = model_size(model)\n",
        "print(f\"Model size: {model_size_mb:.2f} MB\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Ugyt3co8Gc7w"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
